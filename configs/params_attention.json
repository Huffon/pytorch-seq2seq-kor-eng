{
    "model": "seq2seq_attention",
    "save_model": "model_attention.pt",

    "mode": "train",
    "optim": "Adam",

    "random_seed": 32,
    "clip": 1,

    "lr": 1e-3,
    "batch_size": 128,
    "num_epoch": 10,

    "embed_dim": 256,
    "enc_hidden_dim": 512,
    "dec_hidden_dim": 512,
    "n_layer": 1,
    "dropout": 0.5
}